{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKfZPQ4ZjB1nKjpnkg5JgV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manvendra0802/html-port/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQKLz9toceGv",
        "outputId": "f5e1d940-ac07-446c-e3ca-66f8283dd2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# Copy the folder from Google Drive to Colab session storage\n",
        "!cp -r '/content/drive/MyDrive/vlg' '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uS4Dvs2HiZ4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, Add, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from skimage import io, img_as_float\n",
        "import os\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "\n",
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Function to apply radial crop\n",
        "def radial_crop(image, crop_size):\n",
        "    center = (image.shape[0] // 2, image.shape[1] // 2)\n",
        "    radius = min(center[0], center[1], crop_size // 2)\n",
        "    mask = np.zeros((image.shape[0], image.shape[1]), dtype=bool)\n",
        "    Y, X = np.ogrid[:image.shape[0], :image.shape[1]]\n",
        "    dist_from_center = np.sqrt((X - center[1])**2 + (Y - center[0])**2)\n",
        "    mask[dist_from_center <= radius] = True\n",
        "    cropped_image = np.zeros_like(image)\n",
        "    cropped_image[mask] = image[mask]\n",
        "    return resize(cropped_image, (crop_size, crop_size))\n",
        "\n",
        "# Define a simple Residual Block\n",
        "def residual_block(x, filters, kernel_size=(3, 3)):\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = ReLU()(y)\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    return Add()([x, y])\n",
        "\n",
        "# Define the denoising model\n",
        "def build_denoising_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    for _ in range(8):  # Number of residual blocks\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "    outputs = Conv2D(3, (3, 3), padding='same')(x)\n",
        "    outputs = Add()([inputs, outputs])\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Load and preprocess a single image\n",
        "def preprocess_image(img_path, crop_size):\n",
        "    img = img_as_float(io.imread(img_path))\n",
        "    img = radial_crop(img, crop_size)\n",
        "    return img\n",
        "\n",
        "# Data generator for batch processing with augmentation\n",
        "def data_generator(low_folder, high_folder, crop_size, batch_size=32):\n",
        "    low_image_paths = sorted(glob.glob(os.path.join(low_folder, '*.png')))\n",
        "    high_image_paths = sorted(glob.glob(os.path.join(high_folder, '*.png')))\n",
        "\n",
        "    data_gen_args = dict(horizontal_flip=True,\n",
        "                         vertical_flip=True,\n",
        "                         rotation_range=90)\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "    while True:\n",
        "        for i in range(0, len(low_image_paths), batch_size):\n",
        "            low_batch_paths = low_image_paths[i:i + batch_size]\n",
        "            high_batch_paths = high_image_paths[i:i + batch_size]\n",
        "\n",
        "            low_images = np.array([preprocess_image(p, crop_size) for p in low_batch_paths])\n",
        "            high_images = np.array([preprocess_image(p, crop_size) for p in high_batch_paths])\n",
        "\n",
        "            yield low_images, high_images\n",
        "\n",
        "# Custom PSNR metric\n",
        "def psnr(y_true, y_pred):\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
        "\n",
        "# Training function with learning rate scheduling\n",
        "def train_model(low_folder, high_folder, val_low_folder, val_high_folder, crop_size, input_shape, epochs=100, batch_size=16):\n",
        "    model = build_denoising_model(input_shape)\n",
        "    model.compile(optimizer=Adam(1e-4), loss=MeanAbsoluteError(), metrics=[psnr])\n",
        "\n",
        "    steps_per_epoch = len(glob.glob(os.path.join(low_folder, '*.png'))) // batch_size\n",
        "    validation_steps = len(glob.glob(os.path.join(val_low_folder, '*.png'))) // batch_size\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 0.9 ** (epoch // 10))\n",
        "\n",
        "    # Model checkpointing to save best model\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint('denoising1_best_model.h5', monitor='val_psnr', mode='max', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "    # Prepare the dataset\n",
        "    train_ds = tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(low_folder, high_folder, crop_size, batch_size),\n",
        "        output_types=(tf.float32, tf.float32),\n",
        "        output_shapes=((None, crop_size, crop_size, 3), (None, crop_size, crop_size, 3))\n",
        "    )\n",
        "\n",
        "    val_ds = tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(val_low_folder, val_high_folder, crop_size, batch_size),\n",
        "        output_types=(tf.float32, tf.float32),\n",
        "        output_shapes=((None, crop_size, crop_size, 3), (None, crop_size, crop_size, 3))\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_ds,\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              epochs=epochs,\n",
        "              callbacks=[lr_scheduler, checkpoint],\n",
        "              validation_data=val_ds,\n",
        "              validation_steps=validation_steps)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "low_folder = '/content/vlg/Train/low'\n",
        "high_folder = '/content/vlg/Train/high'\n",
        "val_low_folder = '/content/vlg/validate/low'\n",
        "val_high_folder = '/content/vlg/validate/high'\n",
        "\n",
        "# Check if there are files matching the pattern\n",
        "low_image_paths = glob.glob(os.path.join(low_folder, '*.png'))\n",
        "if len(low_image_paths) == 0:\n",
        "    raise ValueError(\"No PNG files found in the directory:\", low_folder)\n",
        "\n",
        "# Determine input shape (256x256x3)\n",
        "crop_size = 256\n",
        "input_shape = (crop_size, crop_size, 3)\n",
        "\n",
        "model = train_model(low_folder, high_folder, val_low_folder, val_high_folder, crop_size, input_shape)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('denoising1_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVuGyZAtcHeF",
        "outputId": "296c09cc-2f29-45d7-e474-f5db9702255e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 67s 2s/step - loss: 0.5678 - psnr: -1.0313 - val_loss: 0.1291 - val_psnr: 12.7022 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 48s 2s/step - loss: 0.3527 - psnr: 3.0199 - val_loss: 0.1446 - val_psnr: 12.5049 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 49s 2s/step - loss: 0.2768 - psnr: 5.4862 - val_loss: 0.1629 - val_psnr: 12.2438 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.2277 - psnr: 7.2632 - val_loss: 0.1221 - val_psnr: 13.4467 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.1853 - psnr: 8.7888 - val_loss: 0.1175 - val_psnr: 13.6911 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.1581 - psnr: 10.0290 - val_loss: 0.1175 - val_psnr: 13.8444 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.1386 - psnr: 11.1068 - val_loss: 0.1135 - val_psnr: 13.6887 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.1393 - psnr: 11.6657 - val_loss: 0.1379 - val_psnr: 13.5045 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.1224 - psnr: 12.6726 - val_loss: 0.1288 - val_psnr: 13.4328 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.1114 - psnr: 13.3223 - val_loss: 0.1339 - val_psnr: 13.7750 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.1037 - psnr: 13.8529 - val_loss: 0.1319 - val_psnr: 14.4375 - lr: 9.0000e-05\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.1045 - psnr: 14.2997 - val_loss: 0.1213 - val_psnr: 14.5699 - lr: 9.0000e-05\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.1041 - psnr: 14.5295 - val_loss: 0.1054 - val_psnr: 15.8767 - lr: 9.0000e-05\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.1062 - psnr: 14.8782 - val_loss: 0.1237 - val_psnr: 15.9719 - lr: 9.0000e-05\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0940 - psnr: 15.4765 - val_loss: 0.1463 - val_psnr: 15.2120 - lr: 9.0000e-05\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0817 - psnr: 16.2229 - val_loss: 0.1649 - val_psnr: 14.8509 - lr: 9.0000e-05\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0902 - psnr: 16.1383 - val_loss: 0.1891 - val_psnr: 13.1346 - lr: 9.0000e-05\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0885 - psnr: 16.1861 - val_loss: 0.1537 - val_psnr: 14.9376 - lr: 9.0000e-05\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0719 - psnr: 16.8718 - val_loss: 0.1581 - val_psnr: 15.0299 - lr: 9.0000e-05\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0692 - psnr: 17.3224 - val_loss: 0.1386 - val_psnr: 15.9821 - lr: 9.0000e-05\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0720 - psnr: 17.4213 - val_loss: 0.1137 - val_psnr: 17.6520 - lr: 8.1000e-05\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 48s 2s/step - loss: 0.0683 - psnr: 17.6721 - val_loss: 0.0973 - val_psnr: 18.3799 - lr: 8.1000e-05\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0673 - psnr: 18.1156 - val_loss: 0.0935 - val_psnr: 17.8834 - lr: 8.1000e-05\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0634 - psnr: 18.4471 - val_loss: 0.1001 - val_psnr: 17.7849 - lr: 8.1000e-05\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 41s 2s/step - loss: 0.0721 - psnr: 18.3431 - val_loss: 0.0929 - val_psnr: 17.5387 - lr: 8.1000e-05\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0576 - psnr: 18.9593 - val_loss: 0.0795 - val_psnr: 17.7893 - lr: 8.1000e-05\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0608 - psnr: 19.0600 - val_loss: 0.0741 - val_psnr: 17.8905 - lr: 8.1000e-05\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0548 - psnr: 19.4290 - val_loss: 0.0659 - val_psnr: 17.4656 - lr: 8.1000e-05\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0595 - psnr: 19.3204 - val_loss: 0.0807 - val_psnr: 17.0046 - lr: 8.1000e-05\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0522 - psnr: 19.7517 - val_loss: 0.0878 - val_psnr: 17.2291 - lr: 8.1000e-05\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0544 - psnr: 19.8310 - val_loss: 0.0809 - val_psnr: 18.2978 - lr: 7.2900e-05\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0580 - psnr: 19.9163 - val_loss: 0.0741 - val_psnr: 18.8115 - lr: 7.2900e-05\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0524 - psnr: 20.1438 - val_loss: 0.0571 - val_psnr: 19.4488 - lr: 7.2900e-05\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0493 - psnr: 20.3793 - val_loss: 0.0614 - val_psnr: 19.8817 - lr: 7.2900e-05\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0505 - psnr: 20.4947 - val_loss: 0.0628 - val_psnr: 19.6427 - lr: 7.2900e-05\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0525 - psnr: 20.5680 - val_loss: 0.0489 - val_psnr: 20.0767 - lr: 7.2900e-05\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0530 - psnr: 20.5732 - val_loss: 0.0591 - val_psnr: 20.3837 - lr: 7.2900e-05\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0496 - psnr: 20.8186 - val_loss: 0.0575 - val_psnr: 20.3799 - lr: 7.2900e-05\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0480 - psnr: 20.8498 - val_loss: 0.0550 - val_psnr: 20.8175 - lr: 7.2900e-05\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0468 - psnr: 21.0389 - val_loss: 0.0484 - val_psnr: 21.0900 - lr: 7.2900e-05\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0442 - psnr: 21.1624 - val_loss: 0.0462 - val_psnr: 21.3319 - lr: 6.5610e-05\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0422 - psnr: 21.3514 - val_loss: 0.0453 - val_psnr: 21.3547 - lr: 6.5610e-05\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0443 - psnr: 21.3054 - val_loss: 0.0542 - val_psnr: 20.6616 - lr: 6.5610e-05\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0426 - psnr: 21.2829 - val_loss: 0.0549 - val_psnr: 20.0792 - lr: 6.5610e-05\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0478 - psnr: 20.9635 - val_loss: 0.0543 - val_psnr: 20.2437 - lr: 6.5610e-05\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0429 - psnr: 21.4706 - val_loss: 0.0567 - val_psnr: 20.5551 - lr: 6.5610e-05\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0425 - psnr: 21.7101 - val_loss: 0.0603 - val_psnr: 20.5997 - lr: 6.5610e-05\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 48s 2s/step - loss: 0.0415 - psnr: 21.7808 - val_loss: 0.0437 - val_psnr: 21.8042 - lr: 6.5610e-05\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0441 - psnr: 21.7800 - val_loss: 0.0418 - val_psnr: 22.0179 - lr: 6.5610e-05\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0396 - psnr: 21.9380 - val_loss: 0.0530 - val_psnr: 21.2086 - lr: 6.5610e-05\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0378 - psnr: 22.1058 - val_loss: 0.0476 - val_psnr: 20.8369 - lr: 5.9049e-05\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.0430 - psnr: 22.0302 - val_loss: 0.0510 - val_psnr: 19.7457 - lr: 5.9049e-05\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 48s 2s/step - loss: 0.0429 - psnr: 22.0693 - val_loss: 0.0595 - val_psnr: 19.5856 - lr: 5.9049e-05\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0428 - psnr: 22.1205 - val_loss: 0.0604 - val_psnr: 19.8777 - lr: 5.9049e-05\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0388 - psnr: 22.3999 - val_loss: 0.0668 - val_psnr: 19.2114 - lr: 5.9049e-05\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0382 - psnr: 22.5581 - val_loss: 0.0540 - val_psnr: 19.3319 - lr: 5.9049e-05\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0412 - psnr: 22.3825 - val_loss: 0.0635 - val_psnr: 19.4317 - lr: 5.9049e-05\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0404 - psnr: 22.4517 - val_loss: 0.0512 - val_psnr: 20.2450 - lr: 5.9049e-05\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0416 - psnr: 22.4309 - val_loss: 0.0467 - val_psnr: 21.2312 - lr: 5.9049e-05\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0391 - psnr: 22.5407 - val_loss: 0.0479 - val_psnr: 22.0564 - lr: 5.9049e-05\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0375 - psnr: 22.6617 - val_loss: 0.0508 - val_psnr: 22.1235 - lr: 5.3144e-05\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0350 - psnr: 22.8920 - val_loss: 0.0378 - val_psnr: 22.5408 - lr: 5.3144e-05\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0369 - psnr: 22.8858 - val_loss: 0.0449 - val_psnr: 22.1258 - lr: 5.3144e-05\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0373 - psnr: 22.8626 - val_loss: 0.0405 - val_psnr: 22.6824 - lr: 5.3144e-05\n",
            "Epoch 65/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0369 - psnr: 22.9907 - val_loss: 0.0492 - val_psnr: 22.2920 - lr: 5.3144e-05\n",
            "Epoch 66/100\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.0352 - psnr: 22.9992 - val_loss: 0.0444 - val_psnr: 22.5439 - lr: 5.3144e-05\n",
            "Epoch 67/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0347 - psnr: 23.0903 - val_loss: 0.0402 - val_psnr: 22.8750 - lr: 5.3144e-05\n",
            "Epoch 68/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0366 - psnr: 23.0145 - val_loss: 0.0344 - val_psnr: 22.9957 - lr: 5.3144e-05\n",
            "Epoch 69/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0331 - psnr: 23.2133 - val_loss: 0.0376 - val_psnr: 22.9977 - lr: 5.3144e-05\n",
            "Epoch 70/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0356 - psnr: 23.1769 - val_loss: 0.0378 - val_psnr: 23.0869 - lr: 5.3144e-05\n",
            "Epoch 71/100\n",
            "27/27 [==============================] - 41s 2s/step - loss: 0.0346 - psnr: 23.2714 - val_loss: 0.0416 - val_psnr: 22.9588 - lr: 4.7830e-05\n",
            "Epoch 72/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0361 - psnr: 23.2631 - val_loss: 0.0496 - val_psnr: 22.2997 - lr: 4.7830e-05\n",
            "Epoch 73/100\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.0374 - psnr: 23.2285 - val_loss: 0.0360 - val_psnr: 22.8294 - lr: 4.7830e-05\n",
            "Epoch 74/100\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.0327 - psnr: 23.4023 - val_loss: 0.0456 - val_psnr: 22.0680 - lr: 4.7830e-05\n",
            "Epoch 75/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0336 - psnr: 23.5175 - val_loss: 0.0486 - val_psnr: 21.7438 - lr: 4.7830e-05\n",
            "Epoch 76/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0347 - psnr: 23.5136 - val_loss: 0.0402 - val_psnr: 21.7806 - lr: 4.7830e-05\n",
            "Epoch 77/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0316 - psnr: 23.6143 - val_loss: 0.0400 - val_psnr: 21.9956 - lr: 4.7830e-05\n",
            "Epoch 78/100\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.0326 - psnr: 23.5880 - val_loss: 0.0404 - val_psnr: 21.4354 - lr: 4.7830e-05\n",
            "Epoch 79/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0360 - psnr: 23.4857 - val_loss: 0.0435 - val_psnr: 20.6370 - lr: 4.7830e-05\n",
            "Epoch 80/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0356 - psnr: 23.4946 - val_loss: 0.0427 - val_psnr: 20.2898 - lr: 4.7830e-05\n",
            "Epoch 81/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0332 - psnr: 23.6220 - val_loss: 0.0554 - val_psnr: 19.8586 - lr: 4.3047e-05\n",
            "Epoch 82/100\n",
            "27/27 [==============================] - 45s 2s/step - loss: 0.0327 - psnr: 23.6645 - val_loss: 0.0477 - val_psnr: 20.5967 - lr: 4.3047e-05\n",
            "Epoch 83/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0325 - psnr: 23.6894 - val_loss: 0.0570 - val_psnr: 20.3254 - lr: 4.3047e-05\n",
            "Epoch 84/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0319 - psnr: 23.7924 - val_loss: 0.0457 - val_psnr: 20.7976 - lr: 4.3047e-05\n",
            "Epoch 85/100\n",
            "27/27 [==============================] - 48s 2s/step - loss: 0.0336 - psnr: 23.6824 - val_loss: 0.0490 - val_psnr: 20.3958 - lr: 4.3047e-05\n",
            "Epoch 86/100\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.0337 - psnr: 23.7847 - val_loss: 0.0472 - val_psnr: 20.6824 - lr: 4.3047e-05\n",
            "Epoch 87/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0325 - psnr: 23.7426 - val_loss: 0.0424 - val_psnr: 21.5769 - lr: 4.3047e-05\n",
            "Epoch 88/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0340 - psnr: 23.6830 - val_loss: 0.0512 - val_psnr: 21.9241 - lr: 4.3047e-05\n",
            "Epoch 89/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0334 - psnr: 23.7496 - val_loss: 0.0378 - val_psnr: 23.5448 - lr: 4.3047e-05\n",
            "Epoch 90/100\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.0359 - psnr: 23.6188 - val_loss: 0.0410 - val_psnr: 23.1126 - lr: 4.3047e-05\n",
            "Epoch 91/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0319 - psnr: 23.7132 - val_loss: 0.0417 - val_psnr: 23.0787 - lr: 3.8742e-05\n",
            "Epoch 92/100\n",
            "27/27 [==============================] - 41s 2s/step - loss: 0.0345 - psnr: 23.5939 - val_loss: 0.0386 - val_psnr: 23.3616 - lr: 3.8742e-05\n",
            "Epoch 93/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0331 - psnr: 23.6991 - val_loss: 0.0380 - val_psnr: 23.4199 - lr: 3.8742e-05\n",
            "Epoch 94/100\n",
            "27/27 [==============================] - 46s 2s/step - loss: 0.0335 - psnr: 23.5283 - val_loss: 0.0370 - val_psnr: 23.3443 - lr: 3.8742e-05\n",
            "Epoch 95/100\n",
            "27/27 [==============================] - 41s 2s/step - loss: 0.0353 - psnr: 23.3502 - val_loss: 0.0387 - val_psnr: 23.0108 - lr: 3.8742e-05\n",
            "Epoch 96/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0344 - psnr: 23.4650 - val_loss: 0.0372 - val_psnr: 23.2028 - lr: 3.8742e-05\n",
            "Epoch 97/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0321 - psnr: 23.5736 - val_loss: 0.0381 - val_psnr: 22.8972 - lr: 3.8742e-05\n",
            "Epoch 98/100\n",
            "27/27 [==============================] - 47s 2s/step - loss: 0.0309 - psnr: 23.6644 - val_loss: 0.0363 - val_psnr: 22.2948 - lr: 3.8742e-05\n",
            "Epoch 99/100\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.0306 - psnr: 23.8130 - val_loss: 0.0395 - val_psnr: 22.0635 - lr: 3.8742e-05\n",
            "Epoch 100/100\n",
            "27/27 [==============================] - 41s 2s/step - loss: 0.0316 - psnr: 23.8520 - val_loss: 0.0455 - val_psnr: 21.6144 - lr: 3.8742e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}